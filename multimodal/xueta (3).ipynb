{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nfrom transformers import AutoConfig, Wav2Vec2Processor\nfrom pathlib import Path\nfrom tqdm import tqdm\nimport os, glob, pickle\nimport torchaudio\nfrom sklearn.model_selection import train_test_split\nimport torchaudio\nimport librosa\nimport IPython.display as ipd\nimport numpy as np\nimport os\nimport sys\nimport torch\nimport torchaudio\nimport librosa\nimport IPython.display as ipd\nimport numpy as np","metadata":{"execution":{"iopub.status.busy":"2022-09-23T21:07:47.022172Z","iopub.execute_input":"2022-09-23T21:07:47.023154Z","iopub.status.idle":"2022-09-23T21:07:51.774864Z","shell.execute_reply.started":"2022-09-23T21:07:47.023037Z","shell.execute_reply":"2022-09-23T21:07:51.771651Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"if torch.cuda.is_available():       \n    device = torch.device(\"cuda\")\n    print(f'There are {torch.cuda.device_count()} GPU(s) available.')\n    print('Device name:', torch.cuda.get_device_name(0))\n\nelse:\n    print('No GPU available, using the CPU instead.')\n    device = torch.device(\"cpu\")","metadata":{"execution":{"iopub.status.busy":"2022-09-23T21:07:51.777451Z","iopub.execute_input":"2022-09-23T21:07:51.778485Z","iopub.status.idle":"2022-09-23T21:07:51.873351Z","shell.execute_reply.started":"2022-09-23T21:07:51.778442Z","shell.execute_reply":"2022-09-23T21:07:51.871980Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"There are 1 GPU(s) available.\nDevice name: Tesla P100-PCIE-16GB\n","output_type":"stream"}]},{"cell_type":"code","source":"from datasets import load_from_disk","metadata":{"execution":{"iopub.status.busy":"2022-09-23T21:07:51.878657Z","iopub.execute_input":"2022-09-23T21:07:51.879118Z","iopub.status.idle":"2022-09-23T21:07:52.428059Z","shell.execute_reply.started":"2022-09-23T21:07:51.879069Z","shell.execute_reply":"2022-09-23T21:07:52.427039Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"train_dataset = load_from_disk('../input/cmu-mosei-small/features/train' )\nval_dataset = load_from_disk('../input/cmu-mosei-small/features/val')\ntest_dataset = load_from_disk('../input/cmu-mosei-small/features/test')","metadata":{"execution":{"iopub.status.busy":"2022-09-23T21:07:52.430743Z","iopub.execute_input":"2022-09-23T21:07:52.431402Z","iopub.status.idle":"2022-09-23T21:07:52.545164Z","shell.execute_reply.started":"2022-09-23T21:07:52.431364Z","shell.execute_reply":"2022-09-23T21:07:52.544100Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"attention_train =[]\ninput_values_train = []\ntrain_labels = []\nids_train = []\nids_att_train = []\nfor i in tqdm(range(len(train_dataset))):\n    if train_dataset[i]['labels'][5] == 0 and train_dataset[i]['labels'][3] == 0: \n        attention_train.append(torch.tensor(train_dataset[i]['attention_mask']))\n        input_values_train.append(torch.tensor(train_dataset[i]['input_values']))\n        lis = (train_dataset[i]['labels'])\n        lis.pop(5)\n        lis.pop(-2)\n        train_labels.append(torch.tensor(lis))\n        ids_train.append(torch.tensor(train_dataset[i]['ids']))\n        ids_att_train.append(torch.tensor(train_dataset[i]['ids_attention']))\n    ","metadata":{"execution":{"iopub.status.busy":"2022-09-23T21:07:52.546560Z","iopub.execute_input":"2022-09-23T21:07:52.547308Z","iopub.status.idle":"2022-09-23T21:28:26.479206Z","shell.execute_reply.started":"2022-09-23T21:07:52.547269Z","shell.execute_reply":"2022-09-23T21:28:26.478176Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stderr","text":"100%|██████████| 3669/3669 [20:33<00:00,  2.97it/s]\n","output_type":"stream"}]},{"cell_type":"code","source":"attention_val =[]\ninput_values_val = []\nval_labels = []\nids_val = []\nids_att_val = []\nfor i in tqdm(range(len(val_dataset))):\n    if val_dataset[i]['labels'][5] == 0 and val_dataset[i]['labels'][3] == 0: \n        \n        attention_val.append(torch.tensor(val_dataset[i]['attention_mask']))\n        input_values_val.append(torch.tensor(val_dataset[i]['input_values']))\n        lis = (val_dataset[i]['labels'])\n        lis.pop(5)\n        lis.pop(-2)\n        val_labels.append(torch.tensor(lis))\n        ids_val.append(torch.tensor(val_dataset[i]['ids']))\n        ids_att_val.append(torch.tensor(val_dataset[i]['ids_attention']))","metadata":{"execution":{"iopub.status.busy":"2022-09-23T21:28:26.480939Z","iopub.execute_input":"2022-09-23T21:28:26.481670Z","iopub.status.idle":"2022-09-23T21:35:11.812097Z","shell.execute_reply.started":"2022-09-23T21:28:26.481631Z","shell.execute_reply":"2022-09-23T21:35:11.811120Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stderr","text":"100%|██████████| 1223/1223 [06:45<00:00,  3.02it/s]\n","output_type":"stream"}]},{"cell_type":"code","source":"attention_test =[]\ninput_values_testl = []\ntest_labels = []\nids_test = []\nids_att_test = []\ntest_emotions = []\nfor i in tqdm(range(len(test_dataset))):\n    if test_dataset[i]['labels'][5] == 0 and test_dataset[i]['labels'][3] == 0: \n        attention_test.append(torch.tensor(test_dataset[i]['attention_mask']))\n        input_values_testl.append(torch.tensor(test_dataset[i]['input_values']))\n        lis = (test_dataset[i]['labels'])\n        lis.pop(5)\n        lis.pop(-2)\n        test_labels.append(torch.tensor(lis))\n        ids_test.append(torch.tensor(test_dataset[i]['ids']))\n        ids_att_test.append(torch.tensor(test_dataset[i]['ids_attention']))","metadata":{"execution":{"iopub.status.busy":"2022-09-23T21:35:11.813183Z","iopub.execute_input":"2022-09-23T21:35:11.813781Z","iopub.status.idle":"2022-09-23T21:42:05.303303Z","shell.execute_reply.started":"2022-09-23T21:35:11.813739Z","shell.execute_reply":"2022-09-23T21:42:05.302266Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stderr","text":"100%|██████████| 1223/1223 [06:53<00:00,  2.96it/s]\n","output_type":"stream"}]},{"cell_type":"code","source":"#input_values_train = torch.stack(input_values_train)\nlabel_list = [ 'happy', 'sad', 'anger',  'disgust']","metadata":{"execution":{"iopub.status.busy":"2022-09-23T21:42:05.304617Z","iopub.execute_input":"2022-09-23T21:42:05.305552Z","iopub.status.idle":"2022-09-23T21:42:05.310711Z","shell.execute_reply.started":"2022-09-23T21:42:05.305514Z","shell.execute_reply":"2022-09-23T21:42:05.309486Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"disgust_tr = 0\nhappy_tr = 0\nsad_tr = 0\nanger_tr = 0\nfor i in range(len(train_labels)):\n    if train_labels[i][0] != 0:\n        happy_tr +=1\n    if train_labels[i][1] != 0:\n        sad_tr +=1\n    if train_labels[i][2] != 0:\n        anger_tr +=1\n    if train_labels[i][3] != 0:\n        disgust_tr +=1","metadata":{"execution":{"iopub.status.busy":"2022-09-23T21:42:05.312308Z","iopub.execute_input":"2022-09-23T21:42:05.312794Z","iopub.status.idle":"2022-09-23T21:42:05.411613Z","shell.execute_reply.started":"2022-09-23T21:42:05.312743Z","shell.execute_reply":"2022-09-23T21:42:05.410693Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"disgust_va = 0\nhappy_va = 0\nsad_va = 0\nanger_va = 0\nfor i in range(len(val_labels)):\n    if val_labels[i][0] != 0:\n        happy_va +=1\n    if val_labels[i][1] != 0:\n        sad_va +=1\n    if val_labels[i][2] != 0:\n        anger_va +=1\n    if val_labels[i][3] != 0:\n        disgust_va +=1","metadata":{"execution":{"iopub.status.busy":"2022-09-23T21:42:05.420887Z","iopub.execute_input":"2022-09-23T21:42:05.421169Z","iopub.status.idle":"2022-09-23T21:42:05.458334Z","shell.execute_reply.started":"2022-09-23T21:42:05.421143Z","shell.execute_reply":"2022-09-23T21:42:05.457467Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"disgust_te = 0\nhappy_te = 0\nsad_te = 0\nanger_te = 0\nfor i in range(len(test_labels)):\n    if test_labels[i][0] != 0:\n        happy_te +=1\n    if test_labels[i][1] != 0:\n        sad_te +=1\n    if test_labels[i][2] != 0:\n        anger_te +=1\n    if test_labels[i][3] != 0:\n        disgust_te +=1","metadata":{"execution":{"iopub.status.busy":"2022-09-23T21:42:05.461497Z","iopub.execute_input":"2022-09-23T21:42:05.461854Z","iopub.status.idle":"2022-09-23T21:42:05.499288Z","shell.execute_reply.started":"2022-09-23T21:42:05.461823Z","shell.execute_reply":"2022-09-23T21:42:05.498404Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"disgust = disgust_te+ disgust_va+disgust_tr\nsad = sad_te+ sad_va+sad_tr\nhappy = happy_te+ happy_va+happy_tr\nanger = anger_te+ anger_va+anger_tr","metadata":{"execution":{"iopub.status.busy":"2022-09-23T21:42:05.502228Z","iopub.execute_input":"2022-09-23T21:42:05.503097Z","iopub.status.idle":"2022-09-23T21:42:05.508622Z","shell.execute_reply.started":"2022-09-23T21:42:05.503055Z","shell.execute_reply":"2022-09-23T21:42:05.507649Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"suma = len(test_labels)+len(val_labels)+len(train_labels)","metadata":{"execution":{"iopub.status.busy":"2022-09-23T21:42:05.509916Z","iopub.execute_input":"2022-09-23T21:42:05.510936Z","iopub.status.idle":"2022-09-23T21:42:05.518354Z","shell.execute_reply.started":"2022-09-23T21:42:05.510901Z","shell.execute_reply":"2022-09-23T21:42:05.517433Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"mean = (happy + sad + anger + disgust)/4\n#pos_wieght = torch.tensor([mean/happy, mean/sad, mean/anger,  mean/disgust]).to('cuda')\npos_wieght = torch.tensor([(suma - happy)/happy, (suma - sad)/sad, (suma - anger)/anger,  (suma - disgust)/disgust]).to('cuda')","metadata":{"execution":{"iopub.status.busy":"2022-09-23T21:42:05.519829Z","iopub.execute_input":"2022-09-23T21:42:05.520212Z","iopub.status.idle":"2022-09-23T21:42:08.393513Z","shell.execute_reply.started":"2022-09-23T21:42:05.520179Z","shell.execute_reply":"2022-09-23T21:42:08.392553Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"from tqdm import tqdm\nfrom torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler","metadata":{"execution":{"iopub.status.busy":"2022-09-23T21:42:08.394883Z","iopub.execute_input":"2022-09-23T21:42:08.395253Z","iopub.status.idle":"2022-09-23T21:42:08.400803Z","shell.execute_reply.started":"2022-09-23T21:42:08.395213Z","shell.execute_reply":"2022-09-23T21:42:08.399859Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"input_values_train = torch.stack(input_values_train)\nattention_train = torch.stack(attention_train)\ntrain_labels = torch.stack(train_labels)\nids_train = torch.stack(ids_train)\nids_att_train = torch.stack(ids_att_train)","metadata":{"execution":{"iopub.status.busy":"2022-09-23T21:42:08.402633Z","iopub.execute_input":"2022-09-23T21:42:08.403293Z","iopub.status.idle":"2022-09-23T21:42:09.814327Z","shell.execute_reply.started":"2022-09-23T21:42:08.403257Z","shell.execute_reply":"2022-09-23T21:42:09.813363Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"input_values_val = torch.stack(input_values_val)\nattention_val = torch.stack(attention_val)\nval_labels = torch.stack(val_labels)\nids_val = torch.stack(ids_val)\nids_att_val = torch.stack(ids_att_val)","metadata":{"execution":{"iopub.status.busy":"2022-09-23T21:42:09.816425Z","iopub.execute_input":"2022-09-23T21:42:09.817002Z","iopub.status.idle":"2022-09-23T21:42:10.333067Z","shell.execute_reply.started":"2022-09-23T21:42:09.816966Z","shell.execute_reply":"2022-09-23T21:42:10.332129Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"input_values_test = torch.stack(input_values_testl)\nattention_test = torch.stack(attention_test)\ntest_labels = torch.stack(test_labels)\nids_test = torch.stack(ids_test)\nids_att_test = torch.stack(ids_att_test)","metadata":{"execution":{"iopub.status.busy":"2022-09-23T21:42:10.348218Z","iopub.execute_input":"2022-09-23T21:42:10.350061Z","iopub.status.idle":"2022-09-23T21:42:11.037239Z","shell.execute_reply.started":"2022-09-23T21:42:10.350016Z","shell.execute_reply":"2022-09-23T21:42:11.036104Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"train = np.zeros(train_labels.shape)\n#print('predictions:',predictions, 'labels:', labels, 'probs', probs)\ntrain[np.where(train_labels >= 0.3)] = 1\ntrain_labels = train\n\nval = np.zeros(val_labels.shape)\n#print('predictions:',predictions, 'labels:', labels, 'probs', probs)\nval[np.where(val_labels >= 0.3)] = 1\nval_labels = val\n\ntest = np.zeros(test_labels.shape)\n#print('predictions:',predictions, 'labels:', labels, 'probs', probs)\ntest[np.where(test_labels >= 0.3)] = 1\ntest_labels = test\n\ntest_labels = torch.tensor(test_labels)\nval_labels = torch.tensor(val_labels)\ntrain_labels = torch.tensor(train_labels)","metadata":{"execution":{"iopub.status.busy":"2022-09-23T21:42:11.042372Z","iopub.execute_input":"2022-09-23T21:42:11.043131Z","iopub.status.idle":"2022-09-23T21:42:11.054160Z","shell.execute_reply.started":"2022-09-23T21:42:11.043094Z","shell.execute_reply":"2022-09-23T21:42:11.053067Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"batch_size = 5\n\n# Create the DataLoader for our training set\ntrain_data = TensorDataset(input_values_train, attention_train, ids_train, ids_att_train, train_labels)\ntrain_sampler = RandomSampler(train_data)\ntrain_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n\n# Create the DataLoader for our validation set\nval_data = TensorDataset(input_values_val, attention_val, ids_val, ids_att_val, val_labels)\nval_sampler = SequentialSampler(val_data)\nval_dataloader = DataLoader(val_data, sampler=val_sampler, batch_size=batch_size)\n\ntest_data = TensorDataset(input_values_test, attention_test, ids_test, ids_att_test, test_labels)\ntest_sampler = SequentialSampler(test_data)\ntest_dataloader = DataLoader(test_data, sampler=test_sampler, batch_size=batch_size)","metadata":{"execution":{"iopub.status.busy":"2022-09-23T21:42:11.056028Z","iopub.execute_input":"2022-09-23T21:42:11.056506Z","iopub.status.idle":"2022-09-23T21:42:11.067308Z","shell.execute_reply.started":"2022-09-23T21:42:11.056467Z","shell.execute_reply":"2022-09-23T21:42:11.066387Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"model_name_or_path = \"lighteternal/wav2vec2-large-xlsr-53-greek\"\npooling_mode = \"mean\"","metadata":{"execution":{"iopub.status.busy":"2022-09-23T21:42:11.068998Z","iopub.execute_input":"2022-09-23T21:42:11.069654Z","iopub.status.idle":"2022-09-23T21:42:11.078470Z","shell.execute_reply.started":"2022-09-23T21:42:11.069619Z","shell.execute_reply":"2022-09-23T21:42:11.077420Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"config = AutoConfig.from_pretrained(\n    model_name_or_path,\n    num_labels=4,\n    label2id={label: i for i, label in enumerate(label_list)},\n    id2label={i: label for i, label in enumerate(label_list)},\n    finetuning_task=\"wav2vec2_clf\",\n)\nsetattr(config, 'pooling_mode', pooling_mode)","metadata":{"execution":{"iopub.status.busy":"2022-09-23T21:42:11.080335Z","iopub.execute_input":"2022-09-23T21:42:11.081101Z","iopub.status.idle":"2022-09-23T21:42:12.138191Z","shell.execute_reply.started":"2022-09-23T21:42:11.081058Z","shell.execute_reply":"2022-09-23T21:42:12.137230Z"},"trusted":true},"execution_count":23,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/1.53k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2d2013cf6b3343a6bf7e2b188436bcc4"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/transformers/configuration_utils.py:359: UserWarning: Passing `gradient_checkpointing` to a config initialization is deprecated and will be removed in v5 Transformers. Using `model.gradient_checkpointing_enable()` instead, or if you are using the `Trainer` API, pass `gradient_checkpointing=True` in your `TrainingArguments`.\n  \"Passing `gradient_checkpointing` to a config initialization is deprecated and will be removed in v5 \"\n","output_type":"stream"}]},{"cell_type":"code","source":"path = 'roberta-base'\nconfig_bert = AutoConfig.from_pretrained(\n    path,\n    num_labels=4,\n    label2id={label: i for i, label in enumerate(label_list)},\n    id2label={i: label for i, label in enumerate(label_list)},\n    finetuning_task=\"roberta_clf\",\n)\n","metadata":{"execution":{"iopub.status.busy":"2022-09-23T21:42:12.139799Z","iopub.execute_input":"2022-09-23T21:42:12.140979Z","iopub.status.idle":"2022-09-23T21:42:13.107599Z","shell.execute_reply.started":"2022-09-23T21:42:12.140942Z","shell.execute_reply":"2022-09-23T21:42:13.106624Z"},"trusted":true},"execution_count":24,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/481 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ea200db141b8481fb6c7d90c411101a1"}},"metadata":{}}]},{"cell_type":"code","source":"import torch","metadata":{"execution":{"iopub.status.busy":"2022-09-23T21:42:13.109073Z","iopub.execute_input":"2022-09-23T21:42:13.110100Z","iopub.status.idle":"2022-09-23T21:42:13.115013Z","shell.execute_reply.started":"2022-09-23T21:42:13.110063Z","shell.execute_reply":"2022-09-23T21:42:13.113983Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"%%time\nimport torch\nimport torch.nn as nn\nfrom transformers import BertModel\nfrom torch.nn import Conv1d\n# Create the BertClassfier class\nclass WAVClassifier(nn.Module):\n    # Bert Model for Classification Tasks.\n    def __init__(self, config, config_bert):\n        \"\"\"\n        @param    bert: a BertModel object\n        @param    classifier: a torch.nn.Module classifier\n        @param    freeze_bert (bool): Set `False` to fine-tune the BERT model\n        \"\"\"\n        super(WAVClassifier, self).__init__()\n        # Specify hidden size of BERT, hidden size of our classifier, and number of labels\n\n        # Instantiate BERT model\n        self.wav2vec2  = Wav2Vec2Model.from_pretrained(\"lighteternal/wav2vec2-large-xlsr-53-greek\", config = config)\n        self.pooling_mode = config.pooling_mode\n        self.classifier_wav = nn.Sequential(\n            nn.Dropout(.25),\n            nn.Linear(config.hidden_size, config.hidden_size //2),\n            #nn.Dropout(0.5),\n         #   nn.ReLU(),  \n            nn.Dropout(.25),\n            nn.Linear(config.hidden_size // 2, config.hidden_size // 4),\n            #nn.ReLU()\n          #  nn.Linear(config.hidden_size // 4, config.num_labels)\n        )\n        \n        self.roberta = RobertaModel.from_pretrained('roberta-base', config = config_bert)\n        self.classifier_text = nn.Sequential(\n            nn.Linear(config_bert.hidden_size, config_bert.hidden_size //2),\n            #nn.ReLU()\n            #nn.Dropout(0.5),\n           # nn.Linear(H, D_out)\n        )\n        \n        self.cnn = nn.Sequential(\n           # nn.Conv1d(config_bert.hidden_size //2 + config.hidden_size // 4, config_bert.hidden_size //4 + config.hidden_size // 8, kernel_size =5),\n            nn.Linear(config_bert.hidden_size //2 + config.hidden_size // 4, config_bert.hidden_size //2 + config.hidden_size // 4) ,\n            nn.Dropout(.10),\n            nn.Linear(config_bert.hidden_size //2 + config.hidden_size // 4, config.num_labels)\n            \n        )\n      \n    def freeze_feature_extractor(self):\n        self.wav2vec2.feature_extractor._freeze_parameters()\n                \n    def merged_strategy(\n            self,\n            hidden_states,\n            mode=\"mean\"\n    ):\n        if mode == \"mean\":\n            outputs = torch.mean(hidden_states, dim=1)\n        elif mode == \"sum\":\n            outputs = torch.sum(hidden_states, dim=1)\n        elif mode == \"max\":\n            outputs = torch.max(hidden_states, dim=1)[0]\n        else:\n            raise Exception(\n                \"The pooling method hasn't been defined! Your pooling mode must be one of these ['mean', 'sum', 'max']\")\n\n        return outputs\n        \n    def forward(self, input_values, attention_mask, input_ids, attention_ids):\n        \"\"\"\n        Feed input to BERT and the classifier to compute logits.\n        @param    input_ids (torch.Tensor): an input tensor with shape (batch_size,\n                      max_length)\n        @param    attention_mask (torch.Tensor): a tensor that hold attention mask\n                      information with shape (batch_size, max_length)\n        @return   logits (torch.Tensor): an output tensor with shape (batch_size,\n                      num_labels)\n        \"\"\"\n        # Feed input to BERT\n        outputs = self.wav2vec2(\n            input_values=input_values,\n            attention_mask=attention_mask\n        )\n        \n        # Extract the last hidden state of the token `[CLS]` for classification task\n        hidden_states = outputs[0]\n        hidden_states = self.merged_strategy(hidden_states, mode=self.pooling_mode)\n\n        # Feed input to classifier to compute logits\n        hidden_speech = self.classifier_wav(hidden_states)\n        outputs_roberta = self.roberta(\n            input_ids=input_ids,\n            attention_mask=attention_ids)\n        last_hidden_state_cls = outputs_roberta[0][:, 0, :]\n        hidden_text = self.classifier_text(last_hidden_state_cls)\n        last = torch.cat(([hidden_speech, hidden_text]), dim = 1)\n        \n        logits = self.cnn(last)\n                \n       # print(logits.shape)\n        return logits","metadata":{"execution":{"iopub.status.busy":"2022-09-23T21:42:13.116612Z","iopub.execute_input":"2022-09-23T21:42:13.117539Z","iopub.status.idle":"2022-09-23T21:42:13.173239Z","shell.execute_reply.started":"2022-09-23T21:42:13.117504Z","shell.execute_reply":"2022-09-23T21:42:13.172084Z"},"trusted":true},"execution_count":26,"outputs":[{"name":"stdout","text":"CPU times: user 30.5 ms, sys: 3 µs, total: 30.6 ms\nWall time: 39.2 ms\n","output_type":"stream"}]},{"cell_type":"code","source":"def initialize_model(epochs=4):\n    \"\"\"Initialize the Bert Classifier, the optimizer and the learning rate scheduler.\n    \"\"\"\n    # Instantiate Bert Classifier\n    wav_classifier = WAVClassifier(config, config_bert)\n\n    # Tell PyTorch to run the model on GPU\n    wav_classifier.to(device)\n\n    # Create the optimizer\n    optimizer = AdamW(wav_classifier.parameters(),\n                      lr=1e-5,    # Default learning rate\n                      eps=1e-8    # Default epsilon value\n                      )\n\n    # Total number of training steps\n    total_steps = len(train_dataloader) * epochs\n\n    # Set up the learning rate scheduler\n    scheduler = get_linear_schedule_with_warmup(\n        optimizer,\n        num_warmup_steps=0, # Default value\n        num_training_steps=total_steps)\n    return wav_classifier, optimizer, scheduler","metadata":{"execution":{"iopub.status.busy":"2022-09-23T21:42:13.174835Z","iopub.execute_input":"2022-09-23T21:42:13.175190Z","iopub.status.idle":"2022-09-23T21:42:13.181343Z","shell.execute_reply.started":"2022-09-23T21:42:13.175157Z","shell.execute_reply":"2022-09-23T21:42:13.180401Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score","metadata":{"execution":{"iopub.status.busy":"2022-09-23T21:42:13.187350Z","iopub.execute_input":"2022-09-23T21:42:13.188094Z","iopub.status.idle":"2022-09-23T21:42:13.192818Z","shell.execute_reply.started":"2022-09-23T21:42:13.188059Z","shell.execute_reply":"2022-09-23T21:42:13.191826Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"\n\n# Specify loss function\nloss_fn = torch.nn.BCEWithLogitsLoss(pos_weight = pos_wieght)\n\ndef set_seed(seed_value=42):\n    \"\"\"Set seed for reproducibility.\n    \"\"\"\n    random.seed(seed_value)\n    np.random.seed(seed_value)\n    torch.manual_seed(seed_value)\n    torch.cuda.manual_seed_all(seed_value)\n\ndef train(model, train_dataloader, val_dataloader=None, epochs=4, evaluation=False):\n    \"\"\"Train the BertClassifier model.\n    \"\"\"\n    # Start training loop\n    print(\"Start training...\\n\")\n    train_history = []\n    best_valid_loss = float('inf')\n    curr_patience = patience = 8\n    num_trials = 3\n    for epoch_i in range(epochs):\n        # =======================================\n        #               Training\n        # =======================================\n        # Print the header of the result table\n        print(f\"{'Epoch':^7} | {'Batch':^7} | {'Train Loss':^12} | {'Val Loss':^10} | {'Val Acc':^9} | {'Elapsed':^9}\")\n        print(\"-\"*70)\n\n        # Measure the elapsed time of each epoch\n        t0_epoch, t0_batch = time.time(), time.time()\n\n        # Reset tracking variables at the beginning of each epoch\n        total_loss, batch_loss, batch_counts = 0, 0, 0\n\n        # Put the model into the training mode\n        model.train()\n\n        # For each batch of training data...\n        for step, batch in enumerate(train_dataloader):\n            batch_counts +=1\n            # Load batch to GPU\n            b_input_values, b_mask, b_input_ids, b_attn_mask, b_labels = tuple(t.to(device) for t in batch)\n\n            # Zero out any previously calculated gradients\n            model.zero_grad()\n\n            # Perform a forward pass. This will return logits.\n            logits = model(b_input_values, b_mask, b_input_ids, b_attn_mask)\n\n            # Compute loss and accumulate the loss values\n            loss = loss_fn(logits, b_labels)\n            train_history.append(loss.cpu().detach().numpy())\n            batch_loss += loss.item()\n            total_loss += loss.item()\n\n            # Perform a backward pass to calculate gradients\n            loss.backward()\n\n            # Clip the norm of the gradients to 1.0 to prevent \"exploding gradients\"\n            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n\n            # Update parameters and the learning rate\n            optimizer.step()\n            scheduler.step()\n\n            # Print the loss values and time elapsed for every 20 batches\n            if (step % 20 == 0 and step != 0) or (step == len(train_dataloader) - 1):\n                # Calculate time elapsed for 20 batches\n                time_elapsed = time.time() - t0_batch\n\n                # Print training results\n                print(f\"{epoch_i + 1:^7} | {step:^7} | {batch_loss / batch_counts:^12.6f} | {'-':^10} | {'-':^9} | {time_elapsed:^9.2f}\")\n\n                # Reset batch tracking variables\n                batch_loss, batch_counts = 0, 0\n                t0_batch = time.time()\n\n        # Calculate the average loss over the entire training data\n        avg_train_loss = total_loss / len(train_dataloader)\n        print(\"-\"*70)\n        # =======================================\n        #               Evaluation\n        # =======================================\n        if evaluation == True:\n            # After the completion of each training epoch, measure the model's performance\n            # on our validation set.\n            val_loss, val_accuracy, curr_patience, best_valid_loss = evaluate(model, val_dataloader, curr_patience, patience, best_valid_loss)\n\n            # Print performance over the entire training data\n            time_elapsed = time.time() - t0_epoch\n            \n            print(f\"{epoch_i + 1:^7} | {'-':^7} | {avg_train_loss:^12.6f} | {val_loss:^10.6f} | {val_accuracy:^9.2f} | {time_elapsed:^9.2f}\")\n            print(\"-\"*70)\n        print(\"\\n\")\n    \n    print(\"Training complete!\")\n    return train_history\n\ndef evaluate(model, val_dataloader, curr_patience, patience, best_valid_loss, treshold=0.5):\n    \"\"\"After the completion of each training epoch, measure the model's performance\n    on our validation set.\n    \"\"\"\n    # Put the model into the evaluation mode. The dropout layers are disabled during\n    # the test time.\n    model.eval()\n\n    # Tracking variables\n    val_accuracy = []\n    val_loss = []\n\n    # For each batch in our validation set...\n    for batch in val_dataloader:\n        # Load batch to GPU\n        b_input_values, b_mask, b_input_ids, b_attn_mask, b_labels = tuple(t.to(device) for t in batch)\n\n        # Compute logits\n        with torch.no_grad():\n            logits = model(b_input_values, b_mask, b_input_ids, b_attn_mask)\n\n        # Compute loss\n        loss = loss_fn(logits, b_labels)\n        val_loss.append(loss.item())\n\n        # Get the predictions\n        preds = logits >= treshold\n\n        # Calculate the accuracy rate\n      #  print(logits)\n       # accuracy = np.mean([(preds[:, i] == b_labels[:, i]).cpu().numpy().mean() for i in range(logits.shape[1])])\n        result = multi_label_metrics(logits, b_labels, treshold)\n        val_accuracy.append(result['accuracy'])\n\n    # Compute the average accuracy and loss over the validation set.\n    val_loss = np.mean(val_loss)\n    val_accuracy = np.mean(val_accuracy)\n\n    if val_loss <= best_valid_loss:\n        best_valid_loss = val_loss\n        print(\"Found new best model on dev set!\")\n        torch.save(model.state_dict(), 'model.std')\n        torch.save(optimizer.state_dict(), 'optim.std')\n        curr_patience = patience\n        \n    else:\n        curr_patience -= 1\n        if curr_patience <= -1:\n            print(\"Running out of patience, loading previous best model.\")\n            num_trials -= 1\n            curr_patience = patience\n            model.load_state_dict(torch.load('model.std'))\n            optimizer.load_state_dict(torch.load('optim.std'))\n            lr_scheduler.step()\n            print(f\"Current learning rate: {optimizer.state_dict()['param_groups'][0]['lr']}\")\n\n    return val_loss, val_accuracy, curr_patience, best_valid_loss\n","metadata":{"execution":{"iopub.status.busy":"2022-09-23T21:42:13.194460Z","iopub.execute_input":"2022-09-23T21:42:13.194931Z","iopub.status.idle":"2022-09-23T21:42:13.354384Z","shell.execute_reply.started":"2022-09-23T21:42:13.194852Z","shell.execute_reply":"2022-09-23T21:42:13.352920Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import f1_score, roc_auc_score, accuracy_score\ndef multi_label_metrics(predictions, labels, threshold=0.5):\n    # first, apply sigmoid on predictions which are of shape (batch_size, num_labels)\n    sigmoid = torch.nn.Sigmoid()\n    #predictions = torch.tensor(predictions)\n   # labels = torch.tensor(labels)\n  #  predictions = predictions.cpu()\n    labels = labels.cpu()\n   # print(predictions)\n   # predictions = torch.stack(predictions, axis = 1)\n    probs = sigmoid(predictions).cpu()\n    # next, use threshold to turn them into integer predictions\n    y_pred = np.zeros(probs.shape)\n    \n    y_pred[np.where(probs >= threshold)] = 1\n    # finally, compute metrics\n    y_true = np.zeros(probs.shape)\n    #print('predictions:',predictions, 'labels:', labels, 'probs', probs)\n   # labels = torch.tensor(labels).cpu()\n    y_true[np.where(labels >= threshold)] = 1\n    y_pred = torch.tensor(y_pred)\n   # print(predictions.shape, y_true.shape)\n    f1_micro_average = f1_score(y_true=y_true, y_pred=y_pred, average='micro')\n    roc_auc = roc_auc_score(y_true, y_pred, average = 'micro')\n    accuracy = accuracy_score(y_true, y_pred)\n    # return as dictionary\n    metrics = {'f1': f1_micro_average,\n               'roc_auc': roc_auc,\n               'accuracy': accuracy,\n               'prediction':y_pred\n              }\n    return metrics","metadata":{"execution":{"iopub.status.busy":"2022-09-23T21:42:13.356297Z","iopub.execute_input":"2022-09-23T21:42:13.356740Z","iopub.status.idle":"2022-09-23T21:42:13.368230Z","shell.execute_reply.started":"2022-09-23T21:42:13.356704Z","shell.execute_reply":"2022-09-23T21:42:13.367224Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nfrom torch.nn import BCEWithLogitsLoss, CrossEntropyLoss, MSELoss\nfrom transformers import AutoConfig, Wav2Vec2Processor,Wav2Vec2ForCTC, Wav2Vec2Tokenizer,BertTokenizer\nfrom transformers.models.wav2vec2.modeling_wav2vec2 import (\n    Wav2Vec2PreTrainedModel,\n    Wav2Vec2Model\n)\nfrom transformers.models.roberta.modeling_roberta import (\n    RobertaPreTrainedModel,\n    RobertaModel\n)","metadata":{"execution":{"iopub.status.busy":"2022-09-23T21:42:13.370192Z","iopub.execute_input":"2022-09-23T21:42:13.370732Z","iopub.status.idle":"2022-09-23T21:42:13.390733Z","shell.execute_reply.started":"2022-09-23T21:42:13.370692Z","shell.execute_reply":"2022-09-23T21:42:13.389883Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\nimport torch.nn.functional as F\nfrom transformers import BertTokenizer, AdamW, get_linear_schedule_with_warmup\nfrom sklearn.model_selection import train_test_split\nfrom sklearn import metrics","metadata":{"execution":{"iopub.status.busy":"2022-09-23T21:42:13.392343Z","iopub.execute_input":"2022-09-23T21:42:13.392657Z","iopub.status.idle":"2022-09-23T21:42:17.537889Z","shell.execute_reply.started":"2022-09-23T21:42:13.392625Z","shell.execute_reply":"2022-09-23T21:42:17.536849Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\npd.set_option('display.max_rows', None)\nimport torch\nimport random\nimport time","metadata":{"execution":{"iopub.status.busy":"2022-09-23T21:42:17.539181Z","iopub.execute_input":"2022-09-23T21:42:17.539527Z","iopub.status.idle":"2022-09-23T21:42:17.546112Z","shell.execute_reply.started":"2022-09-23T21:42:17.539493Z","shell.execute_reply":"2022-09-23T21:42:17.544821Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"wav_classifier, optimizer, scheduler = initialize_model(epochs=10)\ntrain_history = train(wav_classifier, train_dataloader, val_dataloader, epochs=10, evaluation=True)","metadata":{"execution":{"iopub.status.busy":"2022-09-23T21:42:17.547726Z","iopub.execute_input":"2022-09-23T21:42:17.548919Z","iopub.status.idle":"2022-09-23T23:14:55.249721Z","shell.execute_reply.started":"2022-09-23T21:42:17.548882Z","shell.execute_reply":"2022-09-23T23:14:55.248586Z"},"trusted":true},"execution_count":34,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/1.18G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d99325977ada455ebdf56552d212dc68"}},"metadata":{}},{"name":"stderr","text":"Some weights of the model checkpoint at lighteternal/wav2vec2-large-xlsr-53-greek were not used when initializing Wav2Vec2Model: ['lm_head.weight', 'lm_head.bias']\n- This IS expected if you are initializing Wav2Vec2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing Wav2Vec2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/478M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8463545e67224447aa17bb4475d21733"}},"metadata":{}},{"name":"stderr","text":"Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.layer_norm.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.dense.weight']\n- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n/opt/conda/lib/python3.7/site-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n  FutureWarning,\n","output_type":"stream"},{"name":"stdout","text":"Start training...\n\n Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n----------------------------------------------------------------------\n   1    |   20    |   0.921643   |     -      |     -     |   22.70  \n   1    |   40    |   0.917063   |     -      |     -     |   15.21  \n   1    |   60    |   0.882814   |     -      |     -     |   15.67  \n   1    |   80    |   0.821034   |     -      |     -     |   15.66  \n   1    |   100   |   0.917492   |     -      |     -     |   15.62  \n   1    |   120   |   0.877039   |     -      |     -     |   15.56  \n   1    |   140   |   0.937329   |     -      |     -     |   15.55  \n   1    |   160   |   0.949739   |     -      |     -     |   15.30  \n   1    |   180   |   0.939509   |     -      |     -     |   15.58  \n   1    |   200   |   0.873272   |     -      |     -     |   15.41  \n   1    |   220   |   0.870312   |     -      |     -     |   15.68  \n   1    |   240   |   0.921814   |     -      |     -     |   15.37  \n   1    |   260   |   0.872207   |     -      |     -     |   15.62  \n   1    |   280   |   0.991306   |     -      |     -     |   15.29  \n   1    |   300   |   0.860205   |     -      |     -     |   15.44  \n   1    |   320   |   0.873593   |     -      |     -     |   15.57  \n   1    |   340   |   0.873034   |     -      |     -     |   15.48  \n   1    |   360   |   0.867365   |     -      |     -     |   15.32  \n   1    |   380   |   0.907223   |     -      |     -     |   15.07  \n   1    |   400   |   0.915393   |     -      |     -     |   15.43  \n   1    |   420   |   0.842853   |     -      |     -     |   15.71  \n   1    |   440   |   0.911727   |     -      |     -     |   15.43  \n   1    |   460   |   0.852647   |     -      |     -     |   15.39  \n   1    |   480   |   0.881383   |     -      |     -     |   15.49  \n   1    |   500   |   0.809215   |     -      |     -     |   15.17  \n   1    |   520   |   0.895350   |     -      |     -     |   15.51  \n   1    |   540   |   0.882745   |     -      |     -     |   15.32  \n   1    |   560   |   0.838498   |     -      |     -     |   15.66  \n   1    |   580   |   0.894121   |     -      |     -     |   15.49  \n   1    |   600   |   0.823239   |     -      |     -     |   15.34  \n   1    |   620   |   0.837036   |     -      |     -     |   15.59  \n   1    |   632   |   0.907951   |     -      |     -     |   9.16   \n----------------------------------------------------------------------\nFound new best model on dev set!\n   1    |    -    |   0.886226   |  0.830725  |   0.34    |  564.02  \n----------------------------------------------------------------------\n\n\n Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n----------------------------------------------------------------------\n   2    |   20    |   0.784374   |     -      |     -     |   16.22  \n   2    |   40    |   1.019837   |     -      |     -     |   15.41  \n   2    |   60    |   0.885352   |     -      |     -     |   15.58  \n   2    |   80    |   0.792263   |     -      |     -     |   15.26  \n   2    |   100   |   0.804554   |     -      |     -     |   15.55  \n   2    |   120   |   0.768446   |     -      |     -     |   15.47  \n   2    |   140   |   0.839800   |     -      |     -     |   15.14  \n   2    |   160   |   0.831366   |     -      |     -     |   15.56  \n   2    |   180   |   0.786082   |     -      |     -     |   15.22  \n   2    |   200   |   0.918649   |     -      |     -     |   15.47  \n   2    |   220   |   0.795205   |     -      |     -     |   15.38  \n   2    |   240   |   0.856620   |     -      |     -     |   15.25  \n   2    |   260   |   0.832617   |     -      |     -     |   15.53  \n   2    |   280   |   0.806313   |     -      |     -     |   15.50  \n   2    |   300   |   0.812532   |     -      |     -     |   15.20  \n   2    |   320   |   0.818742   |     -      |     -     |   15.46  \n   2    |   340   |   0.799635   |     -      |     -     |   15.40  \n   2    |   360   |   0.827382   |     -      |     -     |   15.27  \n   2    |   380   |   0.828209   |     -      |     -     |   15.65  \n   2    |   400   |   0.848787   |     -      |     -     |   15.72  \n   2    |   420   |   0.833249   |     -      |     -     |   15.34  \n   2    |   440   |   0.824906   |     -      |     -     |   15.66  \n   2    |   460   |   0.782900   |     -      |     -     |   15.31  \n   2    |   480   |   0.783001   |     -      |     -     |   15.47  \n   2    |   500   |   0.818193   |     -      |     -     |   15.39  \n   2    |   520   |   0.791794   |     -      |     -     |   15.47  \n   2    |   540   |   0.738655   |     -      |     -     |   15.50  \n   2    |   560   |   0.736181   |     -      |     -     |   15.38  \n   2    |   580   |   0.901021   |     -      |     -     |   15.65  \n   2    |   600   |   0.874147   |     -      |     -     |   15.34  \n   2    |   620   |   0.815215   |     -      |     -     |   15.73  \n   2    |   632   |   0.825083   |     -      |     -     |   9.18   \n----------------------------------------------------------------------\nFound new best model on dev set!\n   2    |    -    |   0.824338   |  0.809348  |   0.34    |  564.76  \n----------------------------------------------------------------------\n\n\n Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n----------------------------------------------------------------------\n   3    |   20    |   0.765131   |     -      |     -     |   16.05  \n   3    |   40    |   0.798592   |     -      |     -     |   15.88  \n   3    |   60    |   0.862430   |     -      |     -     |   15.28  \n   3    |   80    |   0.751559   |     -      |     -     |   15.37  \n   3    |   100   |   0.822042   |     -      |     -     |   15.57  \n   3    |   120   |   0.775208   |     -      |     -     |   15.77  \n   3    |   140   |   0.788178   |     -      |     -     |   15.35  \n   3    |   160   |   0.755801   |     -      |     -     |   15.71  \n   3    |   180   |   0.862246   |     -      |     -     |   15.36  \n   3    |   200   |   0.869814   |     -      |     -     |   15.47  \n   3    |   220   |   0.795336   |     -      |     -     |   15.27  \n   3    |   240   |   0.798708   |     -      |     -     |   15.37  \n   3    |   260   |   0.782279   |     -      |     -     |   15.54  \n   3    |   280   |   0.704110   |     -      |     -     |   15.57  \n   3    |   300   |   0.783541   |     -      |     -     |   15.43  \n   3    |   320   |   0.802134   |     -      |     -     |   15.52  \n   3    |   340   |   0.673685   |     -      |     -     |   15.43  \n   3    |   360   |   0.831965   |     -      |     -     |   15.42  \n   3    |   380   |   0.681994   |     -      |     -     |   15.41  \n   3    |   400   |   0.638027   |     -      |     -     |   15.47  \n   3    |   420   |   0.830070   |     -      |     -     |   15.39  \n   3    |   440   |   0.777058   |     -      |     -     |   15.62  \n   3    |   460   |   0.764632   |     -      |     -     |   15.54  \n   3    |   480   |   0.727455   |     -      |     -     |   15.51  \n   3    |   500   |   0.712690   |     -      |     -     |   15.49  \n   3    |   520   |   0.793233   |     -      |     -     |   15.58  \n   3    |   540   |   0.826380   |     -      |     -     |   15.48  \n   3    |   560   |   0.719047   |     -      |     -     |   15.45  \n   3    |   580   |   0.725016   |     -      |     -     |   15.42  \n   3    |   600   |   0.619923   |     -      |     -     |   15.39  \n   3    |   620   |   0.728219   |     -      |     -     |   15.29  \n   3    |   632   |   0.741631   |     -      |     -     |   9.42   \n----------------------------------------------------------------------\n   3    |    -    |   0.766184   |  0.829412  |   0.41    |  533.56  \n----------------------------------------------------------------------\n\n\n Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n----------------------------------------------------------------------\n   4    |   20    |   0.692097   |     -      |     -     |   16.45  \n   4    |   40    |   0.742519   |     -      |     -     |   15.48  \n   4    |   60    |   0.711320   |     -      |     -     |   15.48  \n   4    |   80    |   0.672635   |     -      |     -     |   15.64  \n   4    |   100   |   0.612061   |     -      |     -     |   15.78  \n   4    |   120   |   0.677503   |     -      |     -     |   15.59  \n   4    |   140   |   0.657482   |     -      |     -     |   15.39  \n   4    |   160   |   0.664716   |     -      |     -     |   15.60  \n   4    |   180   |   0.751389   |     -      |     -     |   15.60  \n   4    |   200   |   0.673841   |     -      |     -     |   15.41  \n   4    |   220   |   0.645054   |     -      |     -     |   15.56  \n   4    |   240   |   0.666859   |     -      |     -     |   15.41  \n   4    |   260   |   0.704379   |     -      |     -     |   15.78  \n   4    |   280   |   0.754082   |     -      |     -     |   15.66  \n   4    |   300   |   0.659804   |     -      |     -     |   15.71  \n   4    |   320   |   0.767342   |     -      |     -     |   15.32  \n   4    |   340   |   0.666756   |     -      |     -     |   15.40  \n   4    |   360   |   0.691385   |     -      |     -     |   15.48  \n   4    |   380   |   0.744072   |     -      |     -     |   15.32  \n   4    |   400   |   0.656328   |     -      |     -     |   15.34  \n   4    |   420   |   0.734522   |     -      |     -     |   15.68  \n   4    |   440   |   0.697420   |     -      |     -     |   15.51  \n   4    |   460   |   0.683312   |     -      |     -     |   15.52  \n   4    |   480   |   0.714815   |     -      |     -     |   15.44  \n   4    |   500   |   0.647773   |     -      |     -     |   15.57  \n   4    |   520   |   0.747149   |     -      |     -     |   15.42  \n   4    |   540   |   0.720441   |     -      |     -     |   15.36  \n   4    |   560   |   0.748757   |     -      |     -     |   15.35  \n   4    |   580   |   0.713486   |     -      |     -     |   15.27  \n   4    |   600   |   0.669070   |     -      |     -     |   15.56  \n   4    |   620   |   0.708181   |     -      |     -     |   15.37  \n   4    |   632   |   0.831146   |     -      |     -     |   9.36   \n----------------------------------------------------------------------\n   4    |    -    |   0.699205   |  0.839579  |   0.41    |  534.51  \n----------------------------------------------------------------------\n\n\n Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n----------------------------------------------------------------------\n   5    |   20    |   0.673764   |     -      |     -     |   16.39  \n   5    |   40    |   0.620140   |     -      |     -     |   15.57  \n   5    |   60    |   0.606303   |     -      |     -     |   15.37  \n   5    |   80    |   0.707021   |     -      |     -     |   15.45  \n   5    |   100   |   0.622541   |     -      |     -     |   15.73  \n   5    |   120   |   0.571545   |     -      |     -     |   15.41  \n   5    |   140   |   0.719839   |     -      |     -     |   15.47  \n   5    |   160   |   0.631019   |     -      |     -     |   15.35  \n   5    |   180   |   0.587939   |     -      |     -     |   15.39  \n   5    |   200   |   0.635085   |     -      |     -     |   15.54  \n   5    |   220   |   0.656946   |     -      |     -     |   15.34  \n   5    |   240   |   0.660943   |     -      |     -     |   15.40  \n   5    |   260   |   0.736170   |     -      |     -     |   15.52  \n   5    |   280   |   0.615175   |     -      |     -     |   15.58  \n   5    |   300   |   0.533836   |     -      |     -     |   15.62  \n   5    |   320   |   0.643414   |     -      |     -     |   15.26  \n   5    |   340   |   0.622615   |     -      |     -     |   15.50  \n   5    |   360   |   0.575334   |     -      |     -     |   15.38  \n   5    |   380   |   0.639390   |     -      |     -     |   15.52  \n   5    |   400   |   0.577430   |     -      |     -     |   15.62  \n   5    |   420   |   0.632554   |     -      |     -     |   15.52  \n   5    |   440   |   0.636680   |     -      |     -     |   15.45  \n   5    |   460   |   0.710946   |     -      |     -     |   15.67  \n   5    |   480   |   0.574884   |     -      |     -     |   15.53  \n   5    |   500   |   0.596228   |     -      |     -     |   15.60  \n   5    |   520   |   0.804059   |     -      |     -     |   15.46  \n   5    |   540   |   0.668678   |     -      |     -     |   15.75  \n   5    |   560   |   0.702311   |     -      |     -     |   15.47  \n   5    |   580   |   0.663648   |     -      |     -     |   15.48  \n   5    |   600   |   0.638184   |     -      |     -     |   15.63  \n   5    |   620   |   0.711374   |     -      |     -     |   15.54  \n   5    |   632   |   0.587152   |     -      |     -     |   9.27   \n----------------------------------------------------------------------\n   5    |    -    |   0.643348   |  0.916754  |   0.30    |  534.44  \n----------------------------------------------------------------------\n\n\n Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n----------------------------------------------------------------------\n   6    |   20    |   0.572720   |     -      |     -     |   16.39  \n   6    |   40    |   0.659010   |     -      |     -     |   15.32  \n   6    |   60    |   0.556860   |     -      |     -     |   15.48  \n   6    |   80    |   0.599716   |     -      |     -     |   15.37  \n   6    |   100   |   0.617560   |     -      |     -     |   15.69  \n   6    |   120   |   0.666567   |     -      |     -     |   15.26  \n   6    |   140   |   0.581307   |     -      |     -     |   15.47  \n   6    |   160   |   0.548370   |     -      |     -     |   15.59  \n   6    |   180   |   0.572826   |     -      |     -     |   15.71  \n   6    |   200   |   0.405801   |     -      |     -     |   15.34  \n   6    |   220   |   0.612350   |     -      |     -     |   15.54  \n   6    |   240   |   0.589375   |     -      |     -     |   15.56  \n   6    |   260   |   0.537921   |     -      |     -     |   15.48  \n   6    |   280   |   0.579959   |     -      |     -     |   15.58  \n   6    |   300   |   0.709974   |     -      |     -     |   15.56  \n   6    |   320   |   0.528748   |     -      |     -     |   15.47  \n   6    |   340   |   0.656830   |     -      |     -     |   15.43  \n   6    |   360   |   0.599834   |     -      |     -     |   15.47  \n   6    |   380   |   0.589306   |     -      |     -     |   15.46  \n   6    |   400   |   0.493926   |     -      |     -     |   15.42  \n   6    |   420   |   0.742654   |     -      |     -     |   15.56  \n   6    |   440   |   0.619759   |     -      |     -     |   15.37  \n   6    |   460   |   0.607682   |     -      |     -     |   15.24  \n   6    |   480   |   0.515179   |     -      |     -     |   15.34  \n   6    |   500   |   0.620553   |     -      |     -     |   15.62  \n   6    |   520   |   0.518857   |     -      |     -     |   15.59  \n   6    |   540   |   0.707349   |     -      |     -     |   15.62  \n   6    |   560   |   0.623650   |     -      |     -     |   15.50  \n   6    |   580   |   0.597974   |     -      |     -     |   15.39  \n   6    |   600   |   0.575692   |     -      |     -     |   15.62  \n   6    |   620   |   0.626585   |     -      |     -     |   15.43  \n   6    |   632   |   0.647225   |     -      |     -     |   9.22   \n----------------------------------------------------------------------\n   6    |    -    |   0.595636   |  0.946069  |   0.35    |  533.78  \n----------------------------------------------------------------------\n\n\n Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n----------------------------------------------------------------------\n   7    |   20    |   0.506407   |     -      |     -     |   16.22  \n   7    |   40    |   0.615737   |     -      |     -     |   15.37  \n   7    |   60    |   0.484071   |     -      |     -     |   15.41  \n   7    |   80    |   0.533645   |     -      |     -     |   15.30  \n   7    |   100   |   0.533692   |     -      |     -     |   15.68  \n   7    |   120   |   0.455211   |     -      |     -     |   15.48  \n   7    |   140   |   0.493042   |     -      |     -     |   15.41  \n   7    |   160   |   0.588512   |     -      |     -     |   15.51  \n   7    |   180   |   0.567168   |     -      |     -     |   15.52  \n   7    |   200   |   0.539989   |     -      |     -     |   15.54  \n   7    |   220   |   0.624720   |     -      |     -     |   15.61  \n   7    |   240   |   0.574507   |     -      |     -     |   15.44  \n   7    |   260   |   0.422052   |     -      |     -     |   15.64  \n   7    |   280   |   0.523633   |     -      |     -     |   15.49  \n   7    |   300   |   0.492319   |     -      |     -     |   15.45  \n   7    |   320   |   0.585533   |     -      |     -     |   15.42  \n   7    |   340   |   0.612195   |     -      |     -     |   15.15  \n   7    |   360   |   0.546052   |     -      |     -     |   15.50  \n   7    |   380   |   0.611388   |     -      |     -     |   15.45  \n   7    |   400   |   0.552983   |     -      |     -     |   15.37  \n   7    |   420   |   0.536041   |     -      |     -     |   15.48  \n   7    |   440   |   0.566594   |     -      |     -     |   15.73  \n   7    |   460   |   0.506023   |     -      |     -     |   15.57  \n   7    |   480   |   0.478646   |     -      |     -     |   15.46  \n   7    |   500   |   0.609341   |     -      |     -     |   15.67  \n   7    |   520   |   0.535566   |     -      |     -     |   15.57  \n   7    |   540   |   0.553444   |     -      |     -     |   15.50  \n   7    |   560   |   0.475703   |     -      |     -     |   15.37  \n   7    |   580   |   0.581642   |     -      |     -     |   15.42  \n   7    |   600   |   0.539850   |     -      |     -     |   15.63  \n   7    |   620   |   0.589593   |     -      |     -     |   15.72  \n   7    |   632   |   0.674421   |     -      |     -     |   9.10   \n----------------------------------------------------------------------\n   7    |    -    |   0.545506   |  1.016975  |   0.36    |  533.88  \n----------------------------------------------------------------------\n\n\n Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n----------------------------------------------------------------------\n   8    |   20    |   0.490353   |     -      |     -     |   16.12  \n   8    |   40    |   0.507754   |     -      |     -     |   15.34  \n   8    |   60    |   0.474458   |     -      |     -     |   15.56  \n   8    |   80    |   0.498957   |     -      |     -     |   15.54  \n   8    |   100   |   0.589152   |     -      |     -     |   15.54  \n   8    |   120   |   0.538366   |     -      |     -     |   15.44  \n   8    |   140   |   0.580098   |     -      |     -     |   15.55  \n   8    |   160   |   0.594097   |     -      |     -     |   15.30  \n   8    |   180   |   0.496456   |     -      |     -     |   15.39  \n   8    |   200   |   0.486622   |     -      |     -     |   15.46  \n   8    |   220   |   0.509350   |     -      |     -     |   15.46  \n   8    |   240   |   0.506144   |     -      |     -     |   15.46  \n   8    |   260   |   0.492463   |     -      |     -     |   15.58  \n   8    |   280   |   0.517207   |     -      |     -     |   15.53  \n   8    |   300   |   0.532464   |     -      |     -     |   15.23  \n   8    |   320   |   0.427937   |     -      |     -     |   15.46  \n   8    |   340   |   0.440766   |     -      |     -     |   15.23  \n   8    |   360   |   0.582043   |     -      |     -     |   15.40  \n   8    |   380   |   0.602754   |     -      |     -     |   15.51  \n   8    |   400   |   0.476301   |     -      |     -     |   15.43  \n   8    |   420   |   0.518769   |     -      |     -     |   15.60  \n   8    |   440   |   0.449115   |     -      |     -     |   15.38  \n   8    |   460   |   0.426317   |     -      |     -     |   15.34  \n   8    |   480   |   0.383811   |     -      |     -     |   15.48  \n   8    |   500   |   0.549947   |     -      |     -     |   15.29  \n   8    |   520   |   0.540847   |     -      |     -     |   15.29  \n   8    |   540   |   0.520105   |     -      |     -     |   15.56  \n   8    |   560   |   0.500178   |     -      |     -     |   15.31  \n   8    |   580   |   0.596161   |     -      |     -     |   15.59  \n   8    |   600   |   0.562400   |     -      |     -     |   15.66  \n   8    |   620   |   0.501420   |     -      |     -     |   15.36  \n   8    |   632   |   0.487571   |     -      |     -     |   9.41   \n----------------------------------------------------------------------\n   8    |    -    |   0.512160   |  1.061396  |   0.37    |  532.45  \n----------------------------------------------------------------------\n\n\n Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n----------------------------------------------------------------------\n   9    |   20    |   0.476877   |     -      |     -     |   15.95  \n   9    |   40    |   0.458640   |     -      |     -     |   15.57  \n   9    |   60    |   0.438430   |     -      |     -     |   15.79  \n   9    |   80    |   0.436680   |     -      |     -     |   15.42  \n   9    |   100   |   0.491658   |     -      |     -     |   15.49  \n   9    |   120   |   0.488067   |     -      |     -     |   15.19  \n   9    |   140   |   0.505001   |     -      |     -     |   15.42  \n   9    |   160   |   0.492836   |     -      |     -     |   15.81  \n   9    |   180   |   0.467265   |     -      |     -     |   15.05  \n   9    |   200   |   0.515768   |     -      |     -     |   15.09  \n   9    |   220   |   0.477007   |     -      |     -     |   15.33  \n   9    |   240   |   0.391950   |     -      |     -     |   15.61  \n   9    |   260   |   0.566681   |     -      |     -     |   15.39  \n   9    |   280   |   0.528462   |     -      |     -     |   15.33  \n   9    |   300   |   0.603155   |     -      |     -     |   15.63  \n   9    |   320   |   0.468478   |     -      |     -     |   15.71  \n   9    |   340   |   0.493087   |     -      |     -     |   15.33  \n   9    |   360   |   0.463193   |     -      |     -     |   15.52  \n   9    |   380   |   0.411765   |     -      |     -     |   15.20  \n   9    |   400   |   0.455004   |     -      |     -     |   15.73  \n   9    |   420   |   0.568378   |     -      |     -     |   15.53  \n   9    |   440   |   0.451424   |     -      |     -     |   15.57  \n   9    |   460   |   0.448099   |     -      |     -     |   15.24  \n   9    |   480   |   0.432254   |     -      |     -     |   15.63  \n   9    |   500   |   0.529436   |     -      |     -     |   15.43  \n   9    |   520   |   0.505822   |     -      |     -     |   15.33  \n   9    |   540   |   0.479172   |     -      |     -     |   15.50  \n   9    |   560   |   0.427970   |     -      |     -     |   15.29  \n   9    |   580   |   0.483082   |     -      |     -     |   15.38  \n   9    |   600   |   0.483509   |     -      |     -     |   15.59  \n   9    |   620   |   0.560714   |     -      |     -     |   15.50  \n   9    |   632   |   0.538872   |     -      |     -     |   9.23   \n----------------------------------------------------------------------\n   9    |    -    |   0.484898   |  1.102851  |   0.39    |  532.38  \n----------------------------------------------------------------------\n\n\n Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n----------------------------------------------------------------------\n  10    |   20    |   0.455447   |     -      |     -     |   15.92  \n  10    |   40    |   0.489604   |     -      |     -     |   15.40  \n  10    |   60    |   0.390112   |     -      |     -     |   15.28  \n  10    |   80    |   0.511742   |     -      |     -     |   15.55  \n  10    |   100   |   0.486349   |     -      |     -     |   15.26  \n  10    |   120   |   0.466215   |     -      |     -     |   15.58  \n  10    |   140   |   0.533382   |     -      |     -     |   15.27  \n  10    |   160   |   0.546293   |     -      |     -     |   15.56  \n  10    |   180   |   0.410692   |     -      |     -     |   15.47  \n  10    |   200   |   0.483570   |     -      |     -     |   15.56  \n  10    |   220   |   0.464726   |     -      |     -     |   15.47  \n  10    |   240   |   0.482069   |     -      |     -     |   15.45  \n  10    |   260   |   0.434615   |     -      |     -     |   15.29  \n  10    |   280   |   0.468089   |     -      |     -     |   15.30  \n  10    |   300   |   0.540059   |     -      |     -     |   15.56  \n  10    |   320   |   0.481030   |     -      |     -     |   15.52  \n  10    |   340   |   0.537690   |     -      |     -     |   15.19  \n  10    |   360   |   0.392418   |     -      |     -     |   15.38  \n  10    |   380   |   0.434703   |     -      |     -     |   15.44  \n  10    |   400   |   0.416012   |     -      |     -     |   15.26  \n  10    |   420   |   0.408451   |     -      |     -     |   15.22  \n  10    |   440   |   0.503288   |     -      |     -     |   15.35  \n  10    |   460   |   0.459546   |     -      |     -     |   15.60  \n  10    |   480   |   0.520324   |     -      |     -     |   15.61  \n  10    |   500   |   0.409720   |     -      |     -     |   15.29  \n  10    |   520   |   0.447916   |     -      |     -     |   15.64  \n  10    |   540   |   0.498879   |     -      |     -     |   15.25  \n  10    |   560   |   0.363376   |     -      |     -     |   15.44  \n  10    |   580   |   0.510672   |     -      |     -     |   15.34  \n  10    |   600   |   0.416239   |     -      |     -     |   15.67  \n  10    |   620   |   0.553343   |     -      |     -     |   15.26  \n  10    |   632   |   0.452225   |     -      |     -     |   9.41   \n----------------------------------------------------------------------\n  10    |    -    |   0.467952   |  1.099960  |   0.38    |  531.36  \n----------------------------------------------------------------------\n\n\nTraining complete!\n","output_type":"stream"}]},{"cell_type":"code","source":"def predict(input_values_testl,  attention_test, ids_test, ids_att_test, threshold =0.5):\n   # speech = speech_file_to_array_fn(path, sampling_rate)\n   # features = processor(speech, sampling_rate=sampling_rate, return_tensors=\"pt\", padding=True)\n\n    #input_values = features.input_values.to(device)\n    #attention_mask = features.attention_mask.to(device)\n    input_values_testl = torch.tensor(input_values_testl).unsqueeze(0).cuda()\n    attention_test = torch.tensor(attention_test).unsqueeze(0).cuda()\n    ids_test = torch.tensor(ids_test).unsqueeze(0).cuda()\n    ids_att_test = torch.tensor(ids_att_test).unsqueeze(0).cuda()\n    #print(input_values.shape)\n    with torch.no_grad():\n        logits = wav_classifier(input_values_testl, attention_test, ids_test, ids_att_test)\n        \n    #preds = logits.argmax(axis = 1)\n    #accuracy = (preds == labels).cpu().numpy().astype(np.float32)\n    sigmoid = torch.nn.Sigmoid()\n    probs = sigmoid(logits).cpu()\n    y_pred = np.zeros(probs.shape)\n    y_pred[np.where(probs >= threshold)] = 1\n    # finally, compute metrics\n    #print('predictions:',predictions, 'labels:', labels, 'probs', probs)\n    y_pred = torch.tensor(y_pred)\n   # outputs = [{\"Emotion\": config.id2label[i], \"Score\": f\"{round(score * 100, 3):.1f}%\"} for i, score in enumerate(scores)]\n    return y_pred","metadata":{"execution":{"iopub.status.busy":"2022-09-23T23:19:12.894691Z","iopub.execute_input":"2022-09-23T23:19:12.895073Z","iopub.status.idle":"2022-09-23T23:19:12.902903Z","shell.execute_reply.started":"2022-09-23T23:19:12.895042Z","shell.execute_reply":"2022-09-23T23:19:12.901836Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"code","source":"y_pred = []\nfor i in tqdm(range(len(test_data))):\n    y_pred.append(predict(input_values_testl[i], attention_test[i], ids_test[i], ids_att_test[i]))","metadata":{"execution":{"iopub.status.busy":"2022-09-23T23:19:14.712345Z","iopub.execute_input":"2022-09-23T23:19:14.712704Z","iopub.status.idle":"2022-09-23T23:20:38.266965Z","shell.execute_reply.started":"2022-09-23T23:19:14.712672Z","shell.execute_reply":"2022-09-23T23:20:38.265906Z"},"trusted":true},"execution_count":39,"outputs":[{"name":"stderr","text":"  0%|          | 0/1048 [00:00<?, ?it/s]/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  import sys\n/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  \n/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  if __name__ == \"__main__\":\n/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  # Remove the CWD from sys.path while we load stuff.\n100%|██████████| 1048/1048 [01:23<00:00, 12.54it/s]\n","output_type":"stream"}]},{"cell_type":"code","source":"pred = torch.stack(y_pred)\npred = pred[:, 0, :]","metadata":{"execution":{"iopub.status.busy":"2022-09-23T23:25:42.622320Z","iopub.execute_input":"2022-09-23T23:25:42.622901Z","iopub.status.idle":"2022-09-23T23:25:42.629316Z","shell.execute_reply.started":"2022-09-23T23:25:42.622845Z","shell.execute_reply":"2022-09-23T23:25:42.628148Z"},"trusted":true},"execution_count":49,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import classification_report\nprint(classification_report(test_labels, pred, target_names=label_list))","metadata":{"execution":{"iopub.status.busy":"2022-09-23T23:25:54.620236Z","iopub.execute_input":"2022-09-23T23:25:54.620596Z","iopub.status.idle":"2022-09-23T23:25:54.644857Z","shell.execute_reply.started":"2022-09-23T23:25:54.620564Z","shell.execute_reply":"2022-09-23T23:25:54.643757Z"},"trusted":true},"execution_count":50,"outputs":[{"name":"stdout","text":"              precision    recall  f1-score   support\n\n       happy       0.75      0.73      0.74       641\n         sad       0.46      0.61      0.52       300\n       anger       0.45      0.54      0.49       282\n     disgust       0.45      0.50      0.47       232\n\n   micro avg       0.57      0.63      0.60      1455\n   macro avg       0.53      0.60      0.56      1455\nweighted avg       0.59      0.63      0.61      1455\n samples avg       0.63      0.67      0.62      1455\n\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n","output_type":"stream"}]},{"cell_type":"code","source":"from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.datasets import make_multilabel_classification\nfrom sklearn.tree import DecisionTreeClassifier\n\nf, axes = plt.subplots(1, 4, figsize=(25, 15))\naxes = axes.ravel()\nfor i in range(4):\n    disp = ConfusionMatrixDisplay(confusion_matrix(test_labels[:, i],\n                                                   pred[:, i]),\n                                  display_labels=[0, i])\n    disp.plot(ax=axes[i], values_format='.4g')\n    disp.ax_.set_title(f'class {i}')\n    if i<10:\n        disp.ax_.set_xlabel('')\n    if i%5!=0:\n        disp.ax_.set_ylabel('')\n    disp.im_.colorbar.remove()\n\nplt.subplots_adjust(wspace=0.10, hspace=0.1)\nf.colorbar(disp.im_, ax=axes)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-09-23T23:26:13.260270Z","iopub.execute_input":"2022-09-23T23:26:13.260632Z","iopub.status.idle":"2022-09-23T23:26:14.080852Z","shell.execute_reply.started":"2022-09-23T23:26:13.260602Z","shell.execute_reply":"2022-09-23T23:26:14.079732Z"},"trusted":true},"execution_count":51,"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 1800x1080 with 5 Axes>","image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}